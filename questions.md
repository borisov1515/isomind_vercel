# Open Architecture Questions

Эти вопросы были выделены на этапе предварительного планирования архитектуры. 
Они будут дополняться и решаться по мере развития проекта.

### 1. Инфраструктура, Модели и VRAM
* Qwen 2.5-VL 32B — тяжеловесная модель. Как мы планируем умещать инференс (Vision), браузер (Chromium), Xvfb и Moondream 2 на одной карте с 24GB VRAM (уровня RTX 3090/4090)? 
  * Варианты: Квантизация (AWQ/GPTQ, 4-bit), мульти-GPU инстансы, переход на более легкую модель (например, Llama 3.2 11B Vision), либо вынос тяжелого анализа (fallback) через API?

### 2. Захват экрана и триггеры инференса (Polling)
* Ожидание появления элементов может сжечь ресурсы GPU, если делать скриншот и отправлять в модель каждую секунду. Как агент будет понимать, когда можно делать следующий скриншот? 
  * Варианты: Слушать события DOM (`networkidle` / `domcontentloaded` от Playwright) или написать легковесный скрипт детектирования изменений пикселей на экране (Motion detection, image diff)?

### 3. Устойчивость визуальных якорей (Visual Anchors)
* Размер захвата $100 \times 100$ пикселей вокруг курсора может быть слишком жестким (разные разрешения, длинные кнопки "Submit", состояния hover/disabled). 
  * Варианты: Будем ли мы использовать Object Detection (YoloV11, Grounding DINO) для нахождения Bounding Box (границ) элемента перед формированием эмбеддинга, или оставим жесткий кроп?

### 4. Сети и трансляция (WebRTC)
* Облачные узлы (особенно Vast.ai) часто находятся за NAT, и прямой P2P коннект WebRTC в браузер пользователя может не работать примерно на трети машин без дополнительной обвязки.
  * Варианты: Требуется ли закладывать сразу внешний сигнальный сервер и TURN/STUN-сервер (например, Coturn) в первой фазе?
